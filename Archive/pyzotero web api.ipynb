{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully connected to portal library. Total items: 5504\n",
      "INFO:__main__:Successfully connected to search library. Total items: 1456\n",
      "INFO:__main__:Found 31 collections in portal\n",
      "INFO:__main__:Retrieving all items from portal...\n",
      "INFO:__main__:Retrieved 5504 items from portal\n",
      "INFO:__main__:Found 4 collections in search\n",
      "INFO:__main__:Retrieving all items from search...\n",
      "INFO:__main__:Retrieved 1456 items from search\n",
      "INFO:__main__:Retrieving items for duplicate analysis...\n",
      "INFO:__main__:Analysis exported to nechako_analysis\n",
      "INFO:__main__:Retrieving items for duplicate analysis...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis Summary:\n",
      "Portal Library Items: 2166\n",
      "Search Library Items: 768\n",
      "Duplicate Items: 683\n"
     ]
    }
   ],
   "source": [
    "from pyzotero import zotero\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import os\n",
    "\n",
    "class ZoteroGroupAnalyzer:\n",
    "    def __init__(self, api_key):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer with specific Nechako group libraries using API.\n",
    "        \"\"\"\n",
    "        # Initialize with group IDs and API key\n",
    "        self.libraries = {\n",
    "            'portal': zotero.Zotero('364018', 'group', api_key),\n",
    "            'search': zotero.Zotero('5494504', 'group', api_key)\n",
    "        }\n",
    "        \n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Verify connections\n",
    "        for name, zot in self.libraries.items():\n",
    "            try:\n",
    "                # Get first page of items to verify connection\n",
    "                items = zot.items(limit=1)\n",
    "                total = zot.count_items()\n",
    "                self.logger.info(f\"Successfully connected to {name} library. Total items: {total}\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Failed to connect to {name} library: {str(e)}\")\n",
    "                raise\n",
    "\n",
    "    def extract_library_structure(self, library_name):\n",
    "        \"\"\"\n",
    "        Extract complete structure of a group library including collections and items.\n",
    "        \"\"\"\n",
    "        zot = self.libraries[library_name]\n",
    "        structure = {\n",
    "            'collections': [],\n",
    "            'items': [],\n",
    "            'collection_items': []\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Get all collections\n",
    "            collections = zot.collections()\n",
    "            self.logger.info(f\"Found {len(collections)} collections in {library_name}\")\n",
    "            \n",
    "            for coll in collections:\n",
    "                structure['collections'].append({\n",
    "                    'key': coll['key'],\n",
    "                    'name': coll['data']['name'],\n",
    "                    'parent': coll['data'].get('parentCollection', None)\n",
    "                })\n",
    "                \n",
    "                # Get items in this collection\n",
    "                try:\n",
    "                    items = zot.collection_items(coll['key'])\n",
    "                    for item in items:\n",
    "                        structure['collection_items'].append({\n",
    "                            'collection_key': coll['key'],\n",
    "                            'item_key': item['key'],\n",
    "                            'collection_name': coll['data']['name'],\n",
    "                            'title': item['data'].get('title', ''),\n",
    "                            'item_type': item['data'].get('itemType', '')\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    self.logger.warning(f\"Error getting items for collection {coll['data']['name']}: {str(e)}\")\n",
    "            \n",
    "            # Get all items\n",
    "            self.logger.info(f\"Retrieving all items from {library_name}...\")\n",
    "            all_items = zot.everything(zot.items())\n",
    "            structure['items'] = all_items\n",
    "            self.logger.info(f\"Retrieved {len(all_items)} items from {library_name}\")\n",
    "            \n",
    "            return structure\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error extracting structure from {library_name}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def analyze_duplicates(self):\n",
    "        \"\"\"\n",
    "        Compare the two group libraries to find duplicate entries.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get items from both libraries\n",
    "            self.logger.info(\"Retrieving items for duplicate analysis...\")\n",
    "            portal_items = {\n",
    "                item['data']['title'].lower(): item \n",
    "                for item in self.libraries['portal'].everything(self.libraries['portal'].items())\n",
    "                if 'title' in item['data']\n",
    "            }\n",
    "            \n",
    "            search_items = {\n",
    "                item['data']['title'].lower(): item \n",
    "                for item in self.libraries['search'].everything(self.libraries['search'].items())\n",
    "                if 'title' in item['data']\n",
    "            }\n",
    "            \n",
    "            # Find duplicates\n",
    "            duplicate_titles = set(portal_items.keys()) & set(search_items.keys())\n",
    "            \n",
    "            # Create detailed duplicate information\n",
    "            duplicates = []\n",
    "            for title in duplicate_titles:\n",
    "                duplicates.append({\n",
    "                    'title': title,\n",
    "                    'portal_type': portal_items[title]['data'].get('itemType', ''),\n",
    "                    'search_type': search_items[title]['data'].get('itemType', ''),\n",
    "                    'portal_creators': '; '.join(\n",
    "                        f\"{c.get('lastName', '')}, {c.get('firstName', '')}\"\n",
    "                        for c in portal_items[title]['data'].get('creators', [])\n",
    "                    ),\n",
    "                    'search_creators': '; '.join(\n",
    "                        f\"{c.get('lastName', '')}, {c.get('firstName', '')}\"\n",
    "                        for c in search_items[title]['data'].get('creators', [])\n",
    "                    )\n",
    "                })\n",
    "            \n",
    "            # Create visualization\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            venn2([set(portal_items.keys()), set(search_items.keys())],\n",
    "                  set_labels=('Portal Library', 'Search Library'))\n",
    "            plt.title('Library Content Overlap')\n",
    "            plt.savefig('library_overlap.png')\n",
    "            plt.close()\n",
    "            \n",
    "            return {\n",
    "                'duplicates': duplicates,\n",
    "                'stats': {\n",
    "                    'portal_total': len(portal_items),\n",
    "                    'search_total': len(search_items),\n",
    "                    'duplicate_count': len(duplicate_titles)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error analyzing duplicates: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def export_analysis(self, output_dir='nechako_analysis'):\n",
    "        \"\"\"\n",
    "        Export complete analysis to Excel files and visualizations.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create output directory if it doesn't exist\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            # Analyze each library\n",
    "            for lib_name in self.libraries:\n",
    "                structure = self.extract_library_structure(lib_name)\n",
    "                \n",
    "                # Create Excel writer for this library\n",
    "                excel_path = os.path.join(output_dir, f'{lib_name}_library_analysis.xlsx')\n",
    "                with pd.ExcelWriter(excel_path) as writer:\n",
    "                    # Collections sheet\n",
    "                    collections_df = pd.DataFrame(structure['collections'])\n",
    "                    collections_df.to_excel(writer, sheet_name='Collections', index=False)\n",
    "                    \n",
    "                    # Items sheet - extract key metadata\n",
    "                    items_data = []\n",
    "                    for item in structure['items']:\n",
    "                        item_data = item['data']\n",
    "                        items_data.append({\n",
    "                            'key': item['key'],\n",
    "                            'title': item_data.get('title', ''),\n",
    "                            'type': item_data.get('itemType', ''),\n",
    "                            'date': item_data.get('date', ''),\n",
    "                            'creators': '; '.join(\n",
    "                                f\"{c.get('lastName', '')}, {c.get('firstName', '')}\"\n",
    "                                for c in item_data.get('creators', [])\n",
    "                            ),\n",
    "                            'tags': '; '.join(\n",
    "                                t['tag'] for t in item_data.get('tags', [])\n",
    "                            )\n",
    "                        })\n",
    "                    items_df = pd.DataFrame(items_data)\n",
    "                    items_df.to_excel(writer, sheet_name='Items', index=False)\n",
    "                    \n",
    "                    # Collection-Items relationships\n",
    "                    collection_items_df = pd.DataFrame(structure['collection_items'])\n",
    "                    collection_items_df.to_excel(writer, sheet_name='Collection_Items', index=False)\n",
    "            \n",
    "            # Export duplicate analysis\n",
    "            duplicate_analysis = self.analyze_duplicates()\n",
    "            duplicate_path = os.path.join(output_dir, 'duplicate_analysis.xlsx')\n",
    "            with pd.ExcelWriter(duplicate_path) as writer:\n",
    "                # Duplicate items sheet\n",
    "                duplicates_df = pd.DataFrame(duplicate_analysis['duplicates'])\n",
    "                duplicates_df.to_excel(writer, sheet_name='Duplicates', index=False)\n",
    "                \n",
    "                # Statistics sheet\n",
    "                stats_df = pd.DataFrame([duplicate_analysis['stats']])\n",
    "                stats_df.to_excel(writer, sheet_name='Statistics', index=False)\n",
    "            \n",
    "            self.logger.info(f\"Analysis exported to {output_dir}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error exporting analysis: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "def main():\n",
    "    # Replace this with your API key\n",
    "    API_KEY = \"lN8i6KgGqryvsXTHWohCiLVz\"\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = ZoteroGroupAnalyzer(API_KEY)\n",
    "    \n",
    "    # Export full analysis\n",
    "    analyzer.export_analysis()\n",
    "    \n",
    "    # Print summary\n",
    "    duplicate_analysis = analyzer.analyze_duplicates()\n",
    "    print(\"\\nAnalysis Summary:\")\n",
    "    print(f\"Portal Library Items: {duplicate_analysis['stats']['portal_total']}\")\n",
    "    print(f\"Search Library Items: {duplicate_analysis['stats']['search_total']}\")\n",
    "    print(f\"Duplicate Items: {duplicate_analysis['stats']['duplicate_count']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
